\chapter{Methodology}\label{methodology}

Workflow of the research:
\begin{itemize}
    \item Datasets
    \item Documents to passages
    \item Inferring relevance scores of passages
    \item Relevance labels of passages
    \item Transfering relevance labels across datasets
\end{itemize}

\section{Datasets}\label{datasets}

For the selection of datasets, it was important to choosen datasets that are widely used in the field of information retrieval and that already contain relevance judgements. For that reason I decided to use the ClueWeb09 and ClueWeb12 datasets.

\begin{itemize}
    \item What were realy choosen in the final thesis?
    \item Age
    \item Number of queries, documents, qrels
    \item Ancestor datasets (maybe used for transfering relevance labels)
\end{itemize}

\section{Documents to Passages}\label{documents-to-passages}

The first step in the research process was to convert the documents in the datasets to passages. This was done to reduce the size of the documents and to make the relevance judgements more fine-grained.

\begin{itemize}
    \item Why was this step necessary?
    \item How were the documents split into passages?
    \item Usage of \href{https://github.com/grill-lab/trec-cast-tools/tree/master/corpus_processing/passage_chunkers}{trec-cast-tools}
    \item Passage length
    \item Number of passages per document
\end{itemize}

\section{Inferring Relevance Scores of Passages}\label{inferring-relevance-scores-of-passages}

The next step was to infer relevance scores for the passages. This was done by using the relevance judgements, qrels, of the documents in the original datasets. For each qrel in the dataset with a label of 1 or 2, the corresponding passages of the document were used as a query to retrieve the documents of the dataset. 

\begin{itemize}
    \item Why was this step done?
    \item How were the relevance scores inferred?
    \item Usage of \href{https://github.com/joaopalotti/trectools}{trectools}
    \item What is a qrel?
    \item Number of retrieved documents per query
    \item What metrics were used to evaluate the retrieval performance?
\end{itemize}

\section{Relevance Labels of Passages}\label{relevance-labels-of-passages}

The relevance scores of the passages were then used to assign relevance labels to the passages. To do this, I used to open source tool \href{https://github.com/seanmacavaney/autoqrels}{autoqrels}. The tool can be used to automatically assign relevance labels to passages based on the relevance scores of the passages.

\begin{itemize}
    \item Why was this step done?
    \item How were the relevance labels assigned?
    \item Usage of \href{https://github.com/seanmacavaney/autoqrels}{autoqrels}
    \item What is a relevance label?
\end{itemize}


\section{Pairwise Transfering Relevance Labels Across Datasets}\label{pairwise-transfering-relevance-labels-across-datasets}

To transfer relevance labels from the old dataset to the new dataset, the DuoT5 transformer model was utilized. This model takes a query and two documents as input and outputs a relevance score, which represents the probability that the first document is more relevant than the second. Here, a "document" refers to a passage. To assign a relevance label to a passage in the new dataset, it is compared against the top 20 to 30 passages for the same query in the old dataset. Pairwise comparison results and their associated queries are cached to avoid redundant calculations, and the final relevance score is determined by averaging the pairwise results. Two approaches are used to select passages for comparison, as detailed below.

\subsection{Pairwise Preferences Approach 1}\label{pairwise-preferences-approach-1}

This approach identifies 20 to 30 passages from the old dataset most relevant to the query for which the new passage is being labeled. To prevent biases from comparing passages within the same document, all passages from the same document as the first passage are excluded. The first passage is the highest-scoring passage from its document, the second passage is the next highest-scoring passage from another document, and so on. The relevance score for the new passage is then calculated by averaging the scores from pairwise comparisons with the selected top passages.

\subsection{Pairwise Preferences Approach 2}\label{pairwise-preferences-approach-2}

This approach is similar to the first but employs an additional step to eliminate overlaps with the same document. After selecting the highest-scoring passage for a query, the retrieval scores for all passages are recomputed, excluding the document of the already-selected passage from the retrieved documents. This ensures no passages from the same document are used more than once in the comparison. As with the first approach, the final relevance score is obtained by averaging the pairwise comparison scores between the new passage and the top 20 to 30 passages from the old dataset.